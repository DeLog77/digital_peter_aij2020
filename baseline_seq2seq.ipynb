{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence-to-sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Одним из возможных способов улучшения качества системы распознавания рукописных документов является пост-обработка предиктов с помощью модели sequence-to-sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных\n",
    "\n",
    "### В качестве дополнительных данных для обучения модели можно использовать коллекцию текстов 17 века, которая была предложена организаторами соревнования GramEval2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"/home/jovyan/grameval_data/grameval_17_century.txt\"\n",
    "\n",
    "\n",
    "def read_grameval(fname=fname):\n",
    "    with open(fname, \"r\", encoding='utf-8') as f:\n",
    "        lines = [x[:-1] for x in f.readlines()]\n",
    "        return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "grameval_texts = read_grameval(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'и то явное ихъ съ откащикомъ воровство не поставя столба въ отказные книги за споромъ чювашина бортнички написали'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grameval_texts[-5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Зададим набор правил для аугментации данных с использованием шума и специфики стиля Петра I."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "# p of substitution = 1/znam\n",
    "znam = 2\n",
    "\n",
    "rules = []\n",
    "\n",
    "#Традиционно над строкой Петр пишет «з» и «с», конечное «х», также «к» перед широкой размашистой «ж»\n",
    "rules.append(('з',''))\n",
    "rules.append(('c',''))\n",
    "rules.append(('x',''))\n",
    "rules.append(('кж', 'ж'))\n",
    "#вместо старого «ѧ» уже регулярно употребляет вполне современное «я»\n",
    "rules.append(('ѧ', 'я'))\n",
    "#Не любит буквы «s» («зело») и «ѵ» \n",
    "rules.append(('s', ''))\n",
    "rules.append(('ѵ', ''))\n",
    "#Мягкий знак пропускает\n",
    "rules.append(('ь', ''))\n",
    "\n",
    "\n",
    "def replace_letters(line, to_replace, replace_by, znam = 2):\n",
    "    new_line = ''\n",
    "    for letter in line:\n",
    "        if letter == to_replace and random.randint(0, znam - 1) % znam == 0:\n",
    "            new_line = new_line + replace_by\n",
    "        else:\n",
    "            new_line = new_line + letter\n",
    "    return new_line\n",
    "    \n",
    "\n",
    "def apply_rule(lines, rule, znam = 2):\n",
    "    to_replace, replace_by = rule\n",
    "    res = [\n",
    "        replace_letters(line, to_replace, replace_by) for line in lines\n",
    "    ]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peter's writing rules:\n",
      "[('з', ''), ('c', ''), ('x', ''), ('кж', 'ж'), ('ѧ', 'я'), ('s', ''), ('ѵ', ''), ('ь', '')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Peter's writing rules:\")\n",
    "print(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e05bc960bcc4cb9a0730fbf166e6c70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating data...', max=8.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "for rule in tqdm(rules, total=len(rules), desc=\"Generating data...\"):\n",
    "    grameval_texts = apply_rule(grameval_texts, rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построим словарь для генерации шума."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "trans_dir = '/home/jovyan/PETR/baseline/train_test_data/train/words'\n",
    "image_dir = '/home/jovyan/PETR/baseline/train_test_data/train/images'\n",
    "\n",
    "english = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'm', 'n' ,'o', 'p', 'r', 's', 't', 'u', 'w']\n",
    "\n",
    "\n",
    "def process_texts(image_dir,trans_dir):\n",
    "    lens = []\n",
    "    include_english = 0\n",
    "    letters = ''\n",
    "\n",
    "    lines = []\n",
    "    names = []\n",
    "    \n",
    "    all_files = os.listdir(trans_dir)\n",
    "    for filename in os.listdir(image_dir):\n",
    "        if filename[:-3]+'txt' in all_files:\n",
    "            name, ext = os.path.splitext(filename)\n",
    "            txt_filepath = os.path.join(trans_dir, name + '.txt')\n",
    "            with open(txt_filepath, 'r') as file:\n",
    "                data = file.read()\n",
    "                if len(data)==0:\n",
    "                    continue\n",
    "                if len(set(data).intersection(english))>0:\n",
    "                    continue\n",
    "\n",
    "                lines.append(data)\n",
    "                names.append(filename)\n",
    "                lens.append(len(data))\n",
    "                letters += data\n",
    "\n",
    "    print('Максимальная длина строки:', max(lens))\n",
    "    print('Количество строк с английскими буквами ', include_english)\n",
    "\n",
    "    return names,lines,Counter(letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Максимальная длина строки: 63\n",
      "Количество строк с английскими буквами  0\n"
     ]
    }
   ],
   "source": [
    "names, lines, cnt = process_texts(image_dir,trans_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Символы train:   + 0 1 2 3 4 5 6 7 8 9 [ ] i а б в г д е ж з и й к л м н о п р с т у ф х ц ч ш щ ъ ы ь э ю я і ѣ … ⊕ ⊗\n"
     ]
    }
   ],
   "source": [
    "letters = sorted(list(cnt.keys()))\n",
    "print('Символы train:', ' '.join(letters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример аугментации\n",
    "\n",
    "* добавление шума из словаря на посимвольном уровне;\n",
    "* удаление пробелов с определенной вероятностью."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.DataFrame(lines + grameval_texts, columns=[\"trg\"])\n",
    "\n",
    "def add_noise(text, symbols=letters, znam=4):\n",
    "    text = list(text)\n",
    "    num = len(text) // znam\n",
    "    indexes = random.sample(range(0, len(text)), num)\n",
    "    for i in indexes:\n",
    "        if text[i]!=' ':\n",
    "            text[i] = random.choice(symbols)\n",
    "        else:\n",
    "            del_space = np.random.choice([True, False], p=[0.3, 0.7])\n",
    "            if del_space:\n",
    "                text[i] = text[i].replace(\" \", \"\")\n",
    "    return ''.join(text)\n",
    "\n",
    "\n",
    "df[\"src\"] = [add_noise(t, znam=4) for t in df[\"trg\"].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trg</th>\n",
       "      <th>src</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[а iменно при дворѣ аглинском] былъ</td>\n",
       "      <td>[а iм5нпо при ⊗ворѣ ашлинс8ом] бтлъ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>по поставълѣнным с ни</td>\n",
       "      <td>мо 5оставълѣнншм с ну</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>неволником ослабу а астраханца жало</td>\n",
       "      <td>+еволнэ[лм о5лабу а жстраханца жало</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ного не отби</td>\n",
       "      <td>ного ве оцни</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>нее здѣлат и i не допустит до войны</td>\n",
       "      <td>уее здѣлйт и з н7 допустит то ѣойны</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   trg                                  src\n",
       "0  [а iменно при дворѣ аглинском] былъ  [а iм5нпо при ⊗ворѣ ашлинс8ом] бтлъ\n",
       "1                по поставълѣнным с ни                мо 5оставълѣнншм с ну\n",
       "2  неволником ослабу а астраханца жало  +еволнэ[лм о5лабу а жстраханца жало\n",
       "3                         ного не отби                         ного ве оцни\n",
       "4  нее здѣлат и i не допустит до войны  уее здѣлйт и з н7 допустит то ѣойны"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Приведем в пример заранее аугментированные данные, где:\n",
    "\n",
    "* id – id семпла;\n",
    "* src – исходная последовательность;\n",
    "* trg – целевая последовательность;\n",
    "* cn – длина исходной последовательности в символах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>src</th>\n",
       "      <th>trg</th>\n",
       "      <th>cn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>12750</td>\n",
       "      <td>вѣншгра1⊕ а0 гопльдный уже не 2[даси плгда сір...</td>\n",
       "      <td>виноградѣ многоплодный уже не подаси плода сер...</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>50825</td>\n",
       "      <td>всего неметйкихф стяуникфвъ 12… ч</td>\n",
       "      <td>всего неметцкихъ урядниковъ 122 ч</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>114776</td>\n",
       "      <td>⊗ахлвлш кч мнѣ иптинной хриэтобо михаил9 арх⊕н...</td>\n",
       "      <td>паслалъ ко мнѣ истинной христосъ михаила архан...</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>345702</td>\n",
       "      <td>на поляхъ степенныя степемь 13 5лава 28</td>\n",
       "      <td>на поляхъ степенная степень 13 глава 28</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>3048</td>\n",
       "      <td>1 пъшечка нн стаску</td>\n",
       "      <td>1 пушечка на станку</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                                src  \\\n",
       "372   12750  вѣншгра1⊕ а0 гопльдный уже не 2[даси плгда сір...   \n",
       "757   50825                  всего неметйкихф стяуникфвъ 12… ч   \n",
       "512  114776  ⊗ахлвлш кч мнѣ иптинной хриэтобо михаил9 арх⊕н...   \n",
       "15   345702            на поляхъ степенныя степемь 13 5лава 28   \n",
       "595    3048                                1 пъшечка нн стаску   \n",
       "\n",
       "                                                   trg  cn  \n",
       "372  виноградѣ многоплодный уже не подаси плода сер...  76  \n",
       "757                  всего неметцкихъ урядниковъ 122 ч  33  \n",
       "512  паслалъ ко мнѣ истинной христосъ михаила архан...  74  \n",
       "15             на поляхъ степенная степень 13 глава 28  39  \n",
       "595                                1 пушечка на станку  19  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/home/jovyan/grameval_data/augmented_data.csv\", sep=\",\")\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вариант 1: Базовая модель Encoder-Decoder with Bahdanau Attention\n",
    "\n",
    "##### На основе https://bastings.github.io/annotated_encoder_decoder/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install --quiet python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: True\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math, copy, time\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from IPython.core.debugger import set_trace\n",
    "import Levenshtein as lev\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE=torch.device('cuda:0')\n",
    "print(\"CUDA:\", USE_CUDA)\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_seed(seed: int = 42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Архитектура модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A standard Encoder-Decoder architecture. Base for this and many\n",
    "    other models.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoder, decoder, src_embed, trg_embed, generator):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_embed = src_embed\n",
    "        self.trg_embed = trg_embed\n",
    "        self.generator = generator\n",
    "\n",
    "    def forward(self, src, trg, src_mask, trg_mask, src_lengths, trg_lengths):\n",
    "        \"\"\"Take in and process masked src and target sequences.\"\"\"\n",
    "        encoder_hidden, encoder_final = self.encode(src, src_mask, src_lengths)\n",
    "        return self.decode(encoder_hidden, encoder_final, src_mask, trg, trg_mask)\n",
    "\n",
    "    def encode(self, src, src_mask, src_lengths):\n",
    "        return self.encoder(self.src_embed(src), src_mask, src_lengths)\n",
    "\n",
    "    def decode(\n",
    "        self,\n",
    "        encoder_hidden,\n",
    "        encoder_final,\n",
    "        src_mask,\n",
    "        trg,\n",
    "        trg_mask,\n",
    "        decoder_hidden=None,\n",
    "    ):\n",
    "        return self.decoder(\n",
    "            self.trg_embed(trg),\n",
    "            encoder_hidden,\n",
    "            encoder_final,\n",
    "            src_mask,\n",
    "            trg_mask,\n",
    "            hidden=decoder_hidden,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\"Define standard linear + softmax generation step.\"\"\"\n",
    "\n",
    "    def __init__(self, hidden_size, vocab_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.proj = nn.Linear(hidden_size, vocab_size, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.log_softmax(self.proj(x), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"Encodes a sequence of word embeddings\"\"\"\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1, dropout=0.0):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.GRU(\n",
    "            input_size,\n",
    "            hidden_size,\n",
    "            num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mask, lengths):\n",
    "        \"\"\"\n",
    "        Applies a bidirectional GRU to sequence of embeddings x.\n",
    "        The input mini-batch x needs to be sorted by length.\n",
    "        x should have dimensions [batch, time, dim].\n",
    "        \"\"\"\n",
    "        packed = pack_padded_sequence(x, lengths, batch_first=True)\n",
    "        output, final = self.rnn(packed)\n",
    "        output, _ = pad_packed_sequence(output, batch_first=True)\n",
    "\n",
    "        # we need to manually concatenate the final states for both directions\n",
    "        fwd_final = final[0 : final.size(0) : 2]\n",
    "        bwd_final = final[1 : final.size(0) : 2]\n",
    "        # [num_layers, batch, 2*dim]\n",
    "        final = torch.cat([fwd_final, bwd_final], dim=2)\n",
    "\n",
    "        return output, final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\"A conditional RNN decoder with attention.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, emb_size, hidden_size, attention, num_layers=1, dropout=0.5, bridge=True\n",
    "    ):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.attention = attention\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.rnn = nn.GRU(\n",
    "            emb_size + 2 * hidden_size,\n",
    "            hidden_size,\n",
    "            num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "\n",
    "        # to initialize from the final encoder state\n",
    "        self.bridge = (\n",
    "            nn.Linear(2 * hidden_size, hidden_size, bias=True) if bridge else None\n",
    "        )\n",
    "\n",
    "        self.dropout_layer = nn.Dropout(p=dropout)\n",
    "        self.pre_output_layer = nn.Linear(\n",
    "            hidden_size + 2 * hidden_size + emb_size, hidden_size, bias=False\n",
    "        )\n",
    "\n",
    "    def forward_step(self, prev_embed, encoder_hidden, src_mask, proj_key, hidden):\n",
    "        \"\"\"Perform a single decoder step (1 word)\"\"\"\n",
    "\n",
    "        # compute context vector using attention mechanism\n",
    "        query = hidden[-1].unsqueeze(1)  # [#layers, B, D] -> [B, 1, D]\n",
    "        context, attn_probs = self.attention(\n",
    "            query=query, proj_key=proj_key, value=encoder_hidden, mask=src_mask\n",
    "        )\n",
    "\n",
    "        # update rnn hidden state\n",
    "        rnn_input = torch.cat([prev_embed, context], dim=2)\n",
    "        output, hidden = self.rnn(rnn_input, hidden)\n",
    "\n",
    "        pre_output = torch.cat([prev_embed, output, context], dim=2)\n",
    "        pre_output = self.dropout_layer(pre_output)\n",
    "        pre_output = self.pre_output_layer(pre_output)\n",
    "\n",
    "        return output, hidden, pre_output\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        trg_embed,\n",
    "        encoder_hidden,\n",
    "        encoder_final,\n",
    "        src_mask,\n",
    "        trg_mask,\n",
    "        hidden=None,\n",
    "        max_len=None,\n",
    "    ):\n",
    "        \"\"\"Unroll the decoder one step at a time.\"\"\"\n",
    "\n",
    "        # the maximum number of steps to unroll the RNN\n",
    "        if max_len is None:\n",
    "            max_len = trg_mask.size(-1)\n",
    "\n",
    "        # initialize decoder hidden state\n",
    "        if hidden is None:\n",
    "            hidden = self.init_hidden(encoder_final)\n",
    "\n",
    "        # pre-compute projected encoder hidden states\n",
    "        # (the \"keys\" for the attention mechanism)\n",
    "        # this is only done for efficiency\n",
    "        proj_key = self.attention.key_layer(encoder_hidden)\n",
    "\n",
    "        # here we store all intermediate hidden states and pre-output vectors\n",
    "        decoder_states = []\n",
    "        pre_output_vectors = []\n",
    "\n",
    "        # unroll the decoder RNN for max_len steps\n",
    "        for i in range(max_len):\n",
    "            prev_embed = trg_embed[:, i].unsqueeze(1)\n",
    "            output, hidden, pre_output = self.forward_step(\n",
    "                prev_embed, encoder_hidden, src_mask, proj_key, hidden\n",
    "            )\n",
    "            decoder_states.append(output)\n",
    "            pre_output_vectors.append(pre_output)\n",
    "\n",
    "        decoder_states = torch.cat(decoder_states, dim=1)\n",
    "        pre_output_vectors = torch.cat(pre_output_vectors, dim=1)\n",
    "        return decoder_states, hidden, pre_output_vectors  # [B, N, D]\n",
    "\n",
    "    def init_hidden(self, encoder_final):\n",
    "        \"\"\"Returns the initial decoder state,\n",
    "        conditioned on the final encoder state.\"\"\"\n",
    "\n",
    "        if encoder_final is None:\n",
    "            return None  # start with zeros\n",
    "\n",
    "        return torch.tanh(self.bridge(encoder_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    \"\"\"Implements Bahdanau (MLP) attention\"\"\"\n",
    "\n",
    "    def __init__(self, hidden_size, key_size=None, query_size=None):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "\n",
    "        # We assume a bi-directional encoder so key_size is 2*hidden_size\n",
    "        key_size = 2 * hidden_size if key_size is None else key_size\n",
    "        query_size = hidden_size if query_size is None else query_size\n",
    "\n",
    "        self.key_layer = nn.Linear(key_size, hidden_size, bias=False)\n",
    "        self.query_layer = nn.Linear(query_size, hidden_size, bias=False)\n",
    "        self.energy_layer = nn.Linear(hidden_size, 1, bias=False)\n",
    "\n",
    "        # to store attention scores\n",
    "        self.alphas = None\n",
    "\n",
    "    def forward(self, query=None, proj_key=None, value=None, mask=None):\n",
    "        assert mask is not None, \"mask is required\"\n",
    "\n",
    "        # We first project the query (the decoder state).\n",
    "        # The projected keys (the encoder states) were already pre-computated.\n",
    "        query = self.query_layer(query)\n",
    "\n",
    "        # Calculate scores.\n",
    "        scores = self.energy_layer(torch.tanh(query + proj_key))\n",
    "        scores = scores.squeeze(2).unsqueeze(1)\n",
    "\n",
    "        # Mask out invalid positions.\n",
    "        # The mask marks valid positions so we invert it using `mask & 0`.\n",
    "        scores.data.masked_fill_(mask == 0, -float(\"inf\"))\n",
    "\n",
    "        # Turn scores to probabilities.\n",
    "        alphas = F.softmax(scores, dim=-1)\n",
    "        self.alphas = alphas\n",
    "\n",
    "        # The context vector is the weighted sum of the values.\n",
    "        context = torch.bmm(alphas, value)\n",
    "\n",
    "        # context shape: [B, 1, 2D], alphas shape: [B, 1, M]\n",
    "        return context, alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch:\n",
    "    def __init__(self, src, trg, pad_index=0):\n",
    "\n",
    "        src, src_lengths = src\n",
    "\n",
    "        self.src = src\n",
    "        self.src_lengths = src_lengths\n",
    "        self.src_mask = (src != pad_index).unsqueeze(-2)\n",
    "        self.nseqs = src.size(0)\n",
    "\n",
    "        self.trg = None\n",
    "        self.trg_y = None\n",
    "        self.trg_mask = None\n",
    "        self.trg_lengths = None\n",
    "        self.ntokens = None\n",
    "\n",
    "        if trg is not None:\n",
    "            trg, trg_lengths = trg\n",
    "            self.trg = trg[:, :-1]\n",
    "            self.trg_lengths = trg_lengths\n",
    "            self.trg_y = trg[:, 1:]\n",
    "            self.trg_mask = self.trg_y != pad_index\n",
    "            self.ntokens = (self.trg_y != pad_index).data.sum().item()\n",
    "\n",
    "        if USE_CUDA:\n",
    "            self.src = self.src.cuda()\n",
    "            self.src_mask = self.src_mask.cuda()\n",
    "\n",
    "            if trg is not None:\n",
    "                self.trg = self.trg.cuda()\n",
    "                self.trg_y = self.trg_y.cuda()\n",
    "                self.trg_mask = self.trg_mask.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLossCompute:\n",
    "    def __init__(self, generator, criterion, opt=None):\n",
    "        self.generator = generator\n",
    "        self.criterion = criterion\n",
    "        self.opt = opt\n",
    "\n",
    "    def __call__(self, x, y, norm):\n",
    "        x = self.generator(x)\n",
    "        loss = self.criterion(\n",
    "            x.contiguous().view(-1, x.size(-1)), y.contiguous().view(-1)\n",
    "        )\n",
    "        loss = loss / norm\n",
    "\n",
    "        if self.opt is not None:\n",
    "            loss.backward()\n",
    "            self.opt.step()\n",
    "            self.opt.zero_grad()\n",
    "\n",
    "        return loss.data.item() * norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(\n",
    "    src_vocab, tgt_vocab, emb_size=256, hidden_size=512, num_layers=1, dropout=0.1\n",
    "):\n",
    "    \"Helper: Construct a model from hyperparameters.\"\n",
    "\n",
    "    attention = BahdanauAttention(hidden_size)\n",
    "\n",
    "    model = EncoderDecoder(\n",
    "        Encoder(emb_size, hidden_size, num_layers=num_layers, dropout=dropout),\n",
    "        Decoder(\n",
    "            emb_size, hidden_size, attention, num_layers=num_layers, dropout=dropout\n",
    "        ),\n",
    "        nn.Embedding(src_vocab, emb_size),\n",
    "        nn.Embedding(tgt_vocab, emb_size),\n",
    "        Generator(hidden_size, tgt_vocab),\n",
    "    )\n",
    "\n",
    "    return model.cuda() if USE_CUDA else model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_examples(\n",
    "    example_iter,\n",
    "    model,\n",
    "    n=2,\n",
    "    max_len=256,\n",
    "    src_vocab=None,\n",
    "    trg_vocab=None,\n",
    "):\n",
    "    \"\"\"Prints N examples. Assumes batch size of 1.\"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    count = 0\n",
    "    print()\n",
    "\n",
    "    if src_vocab is not None and trg_vocab is not None:\n",
    "        src_eos_index = src_vocab.stoi[EOS_TOKEN]\n",
    "        trg_sos_index = trg_vocab.stoi[SOS_TOKEN]\n",
    "        trg_eos_index = trg_vocab.stoi[EOS_TOKEN]\n",
    "    else:\n",
    "        src_eos_index = None\n",
    "        trg_sos_index = 1\n",
    "        trg_eos_index = None\n",
    "\n",
    "    for i, batch in enumerate(example_iter):\n",
    "\n",
    "        src = batch.src.cpu().numpy()[0, :]\n",
    "        trg = batch.trg_y.cpu().numpy()[0, :]\n",
    "\n",
    "        src = src[:-1] if src[-1] == src_eos_index else src\n",
    "        trg = trg[:-1] if trg[-1] == trg_eos_index else trg\n",
    "\n",
    "        result, _ = greedy_decode(\n",
    "            model,\n",
    "            batch.src,\n",
    "            batch.src_mask,\n",
    "            batch.src_lengths,\n",
    "            max_len=max_len,\n",
    "            sos_index=trg_sos_index,\n",
    "            eos_index=trg_eos_index,\n",
    "        )\n",
    "        print(\"Example #%d\" % (i + 1))\n",
    "        print(\"Src : \", \" \".join(lookup_words(src, vocab=src_vocab)))\n",
    "        print(\"Trg : \", \" \".join(lookup_words(trg, vocab=trg_vocab)))\n",
    "        print(\"Pred: \", \" \".join(lookup_words(result, vocab=trg_vocab)))\n",
    "        print()\n",
    "\n",
    "        count += 1\n",
    "        if count == n:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import data, datasets\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    return list(text)\n",
    "\n",
    "\n",
    "PAD_TOKEN = \"{\"\n",
    "SOS_TOKEN = \"~\"\n",
    "EOS_TOKEN = \"^\"\n",
    "UNK_TOKEN = \"&\"\n",
    "\n",
    "\n",
    "ID = data.Field(sequential=False, use_vocab=False)\n",
    "\n",
    "SOURCE = data.Field(\n",
    "    tokenize=tokenize,\n",
    "    batch_first=True,\n",
    "    lower=False,\n",
    "    include_lengths=True,\n",
    "    unk_token=UNK_TOKEN,\n",
    "    pad_token=PAD_TOKEN,\n",
    "    init_token=None,\n",
    "    eos_token=EOS_TOKEN,\n",
    ")\n",
    "\n",
    "TARGET = data.Field(\n",
    "    tokenize=tokenize,\n",
    "    batch_first=True,\n",
    "    lower=False,\n",
    "    include_lengths=True,\n",
    "    unk_token=UNK_TOKEN,\n",
    "    pad_token=PAD_TOKEN,\n",
    "    init_token=SOS_TOKEN,\n",
    "    eos_token=EOS_TOKEN,\n",
    ")\n",
    "\n",
    "LEN = data.Field(sequential=False, use_vocab=False)\n",
    "\n",
    "data_fields = [(\"id\", ID), (\"src\", SOURCE), (\"trg\", TARGET), (\"cn\", LEN)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "encoder_decoder_model_path = \"encoder_decoder_model\"\n",
    "\n",
    "\n",
    "if not os.path.exists(encoder_decoder_model_path):\n",
    "    os.makedirs(encoder_decoder_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/jovyan/grameval_data/augmented_data.csv\"\n",
    "\n",
    "encoder_decoder_data = data.TabularDataset(\n",
    "    path=data_path, format=\"csv\", skip_header=True, fields=data_fields\n",
    ")\n",
    "\n",
    "train_data, dev_data = encoder_decoder_data.split(\n",
    "    split_ratio=[0.9, 0.1], stratified=True, strata_field=\"cn\"\n",
    ")\n",
    "\n",
    "SOURCE.build_vocab(train_data.src)\n",
    "TARGET.build_vocab(train_data.trg)\n",
    "PAD_INDEX = TARGET.vocab.stoi[PAD_TOKEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "\n",
    "train_iter = data.BucketIterator(\n",
    "    train_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    train=True,\n",
    "    sort_within_batch=True,\n",
    "    sort_key=lambda x: (len(x.src), len(x.trg)),\n",
    "    repeat=False,\n",
    "    device=DEVICE,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "valid_iter_batch = data.Iterator(\n",
    "    dev_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    train=False,\n",
    "    sort_within_batch=True,\n",
    "    sort_key=lambda x: (len(x.src), len(x.trg)),\n",
    "    repeat=False,\n",
    "    device=DEVICE,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebatch(pad_idx, batch):\n",
    "    \"\"\"Wrap torchtext batch into our own Batch class for pre-processing\"\"\"\n",
    "    return Batch(batch.src, batch.trg, pad_idx)\n",
    "\n",
    "\n",
    "def run_epoch(data_iter, model, loss_compute, print_every=50, num_batches=100):\n",
    "    \"\"\"Standard Training and Logging Function\"\"\"\n",
    "\n",
    "    start = time.time()\n",
    "    total_loss = 0\n",
    "    print_tokens = 0\n",
    "    total_tokens = 0\n",
    "\n",
    "    with tqdm(total=num_batches) as pbar:\n",
    "        for i, batch in enumerate(data_iter, 1):\n",
    "\n",
    "            out, _, pre_output = model.forward(\n",
    "                batch.src,\n",
    "                batch.trg,\n",
    "                batch.src_mask,\n",
    "                batch.trg_mask,\n",
    "                batch.src_lengths,\n",
    "                batch.trg_lengths,\n",
    "            )\n",
    "            loss = loss_compute(pre_output, batch.trg_y, batch.nseqs)\n",
    "            total_loss += loss\n",
    "            print_tokens += batch.ntokens\n",
    "            total_tokens += batch.ntokens\n",
    "\n",
    "            if model.training and i % print_every == 0:\n",
    "                elapsed = time.time() - start\n",
    "                print(\n",
    "                    \"Epoch Step: %d Loss: %f Tokens per Sec: %f\"\n",
    "                    % (i, loss / batch.nseqs, print_tokens / elapsed)\n",
    "                )\n",
    "                start = time.time()\n",
    "                print_tokens = 0\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "    loss = total_loss / float(total_tokens)\n",
    "    perplexity = math.exp(loss)\n",
    "\n",
    "    return perplexity, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_batch(batch, vocab, target=True):\n",
    "    res = []\n",
    "    eos_index = vocab.stoi[EOS_TOKEN]\n",
    "    batch = batch.trg.tolist() if target else batch.src.tolist()\n",
    "    for s in batch:\n",
    "        first_eos = np.where(np.array(s) == eos_index)[0]\n",
    "        if len(first_eos) > 0:\n",
    "            res.append(\n",
    "                \"\".join(lookup_words(s[: first_eos[0]], vocab=vocab))\n",
    "                .replace(\"~\", \"\")\n",
    "                .strip()\n",
    "            )\n",
    "        else:\n",
    "            res.append(\n",
    "                \"\".join(lookup_words(s[:], vocab=vocab)).replace(\"~\", \"\").strip()\n",
    "            )\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 256\n",
    "\n",
    "\n",
    "def greedy_decode_batch(\n",
    "    model, src, src_mask, src_lengths, max_len=MAX_LEN, sos_index=1, eos_index=None\n",
    "):\n",
    "    \"\"\"Greedily decode a sentence.\"\"\"\n",
    "    batch_size = src.size(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        encoder_hidden, encoder_final = model.encode(src, src_mask, src_lengths)\n",
    "        prev_y = torch.ones(batch_size, 1).fill_(sos_index).type_as(src)\n",
    "        trg_mask = torch.ones_like(prev_y)\n",
    "\n",
    "    output, hidden = [], None\n",
    "\n",
    "    for i in range(max_len):\n",
    "        with torch.no_grad():\n",
    "            out, hidden, pre_output = model.decode(\n",
    "                encoder_hidden, encoder_final, src_mask, prev_y, trg_mask, hidden\n",
    "            )\n",
    "            prob = model.generator(pre_output[:, -1])\n",
    "\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.data\n",
    "        output.append(next_word.cpu().numpy())\n",
    "        prev_y = next_word.unsqueeze(dim=1)\n",
    "\n",
    "    output = np.array(output)\n",
    "    output = np.stack(output).T\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def predict(\n",
    "    example_iter,\n",
    "    model,\n",
    "    max_len=MAX_LEN,\n",
    "    src_vocab=None,\n",
    "    trg_vocab=None,\n",
    "    num_batches=100,\n",
    "):\n",
    "    model.eval()\n",
    "\n",
    "    if src_vocab is not None and trg_vocab is not None:\n",
    "        trg_sos_index = trg_vocab.stoi[SOS_TOKEN]\n",
    "        trg_eos_index = trg_vocab.stoi[EOS_TOKEN]\n",
    "    else:\n",
    "        trg_sos_index = 1\n",
    "        trg_eos_index = None\n",
    "\n",
    "    preds, sources, targets = [], [], []\n",
    "\n",
    "    with tqdm(total=num_batches) as pbar:\n",
    "        for i, batch in enumerate(example_iter):\n",
    "\n",
    "            source_batch = translate_batch(batch, vocab=SOURCE.vocab, target=False)\n",
    "            target_batch = translate_batch(batch, vocab=TARGET.vocab, target=True)\n",
    "\n",
    "            sources.extend(source_batch)\n",
    "            targets.extend(target_batch)\n",
    "\n",
    "            output = greedy_decode_batch(\n",
    "                model,\n",
    "                batch.src,\n",
    "                batch.src_mask,\n",
    "                batch.src_lengths,\n",
    "                max_len=max_len,\n",
    "                sos_index=trg_sos_index,\n",
    "                eos_index=trg_eos_index,\n",
    "            )\n",
    "\n",
    "            if trg_eos_index is not None:\n",
    "                for pred in output:\n",
    "                    if type(pred) == list:\n",
    "                        pred = np.array(pred)\n",
    "                    first_eos = np.where(pred == trg_eos_index)[0]\n",
    "                    if len(first_eos) > 0:\n",
    "                        # produce sentences\n",
    "                        preds.append(\n",
    "                            \"\".join(lookup_words(pred[: first_eos[0]], vocab=trg_vocab))\n",
    "                        )\n",
    "                    else:\n",
    "                        preds.append(\"\".join(lookup_words(pred[:], vocab=trg_vocab)))\n",
    "            pbar.update(1)\n",
    "    return preds, sources, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(tr_loss, tr_ppl, val_loss, val_ppl):\n",
    "    res = {\n",
    "        \"Train Loss\": np.mean(tr_loss),\n",
    "        \"Train PPL\": np.mean(tr_ppl),\n",
    "        \"Validation Loss\": np.mean(val_loss),\n",
    "        \"Validation PPL\": np.mean(val_ppl)\n",
    "    }\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def save_json(fname, obj):\n",
    "    with open(fname, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(obj, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "def save_results(all_predictions, all_targets, all_sources, model_path=encoder_decoder_model_path):\n",
    "    res = {\n",
    "        \"predictions\": all_predictions,\n",
    "        \"targets\": all_targets,\n",
    "        \"sources\": all_sources,\n",
    "    }\n",
    "\n",
    "    save_json(os.path.join(model_path, \"encoder_decoder_results.json\"), res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model, criterion, optim, source_vocab, target_vocab, num_epochs=10, print_every=500, model_path=encoder_decoder_model_path\n",
    "):\n",
    "    if USE_CUDA:\n",
    "        model.cuda()\n",
    "\n",
    "    train_losses, valid_losses = [], []\n",
    "    train_perplexities, valid_perplexities = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch = epoch + 1\n",
    "        print(\"Epoch\", epoch)\n",
    "        print(\"Training the model\")\n",
    "        model.train()\n",
    "\n",
    "        train_perplexity, train_loss = run_epoch(\n",
    "            (rebatch(PAD_INDEX, b) for b in train_iter),\n",
    "            model,\n",
    "            SimpleLossCompute(model.generator, criterion, optim),\n",
    "            print_every=print_every,\n",
    "            num_batches=len(train_iter),\n",
    "        )\n",
    "\n",
    "        print(\"Train Loss: %f\" % train_loss)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            print(\"Evaluating the model\")\n",
    "            # print_examples((rebatch(PAD_INDEX, x) for x in valid_iter), model, n=3, src_vocab=source_vocab.vocab, trg_vocab=target_vocab.vocab)\n",
    "            dev_perplexity, dev_loss = run_epoch(\n",
    "                (rebatch(PAD_INDEX, b) for b in valid_iter_batch),\n",
    "                model,\n",
    "                SimpleLossCompute(model.generator, criterion, None),\n",
    "                num_batches=len(valid_iter_batch),\n",
    "            )\n",
    "\n",
    "            train_losses.append(train_loss)\n",
    "            train_perplexities.append(train_perplexity)\n",
    "            valid_losses.append(dev_loss)\n",
    "            valid_perplexities.append(dev_perplexity)\n",
    "\n",
    "            print(\"*\" * 30)\n",
    "            print(\"Epoch metrics\\n\")\n",
    "            print(\"Validation perplexity: %3.f \\n\" % dev_perplexity)\n",
    "            print(\"Validation Loss: %3.f \" % dev_loss)\n",
    "\n",
    "            print(\"*\" * 30)\n",
    "\n",
    "            if epoch == num_epochs:\n",
    "                model_name = os.path.join(model_path, \"encoder_decoder_model.pt\")\n",
    "\n",
    "                print(\"Saving model %s\" % model_name)\n",
    "\n",
    "                torch.save(model.state_dict(), model_name)\n",
    "\n",
    "                preds, sources, targets = predict(\n",
    "                    (rebatch(PAD_INDEX, x) for x in valid_iter_batch),\n",
    "                    model,\n",
    "                    max_len=MAX_LEN,\n",
    "                    src_vocab=source_vocab.vocab,\n",
    "                    trg_vocab=target_vocab.vocab,\n",
    "                    num_batches=len(valid_iter_batch),\n",
    "                )\n",
    "\n",
    "                save_results(preds, targets, sources)\n",
    "\n",
    "    return train_perplexities, valid_perplexities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_words(x, vocab=None):\n",
    "    if vocab is not None:\n",
    "        x = [vocab.itos[i] for i in x]\n",
    "    return [str(t) for t in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_SIZE = 256\n",
    "HIDDEN_SIZE = 512\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT_RATE = 0.25\n",
    "LEARNING_RATE = 2*1e-5\n",
    "\n",
    "model = make_model(\n",
    "    len(SOURCE.vocab),\n",
    "    len(TARGET.vocab),\n",
    "    emb_size=EMB_SIZE,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dropout=DROPOUT_RATE,\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(reduction=\"sum\", ignore_index=PAD_INDEX)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 15\n",
    "PRINT_EVERY = 500\n",
    "\n",
    "train_perplexities, valid_perplexities = train(\n",
    "    model=model,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    print_every=PRINT_EVERY,\n",
    "    criterion=criterion,\n",
    "    optim=optim,\n",
    "    source_vocab=SOURCE,\n",
    "    target_vocab=TARGET,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppls = {\n",
    "    \"train\": train_perplexities,\n",
    "    \"val\": valid_perplexities\n",
    "}\n",
    "\n",
    "\n",
    "save_json(\n",
    "    os.path.join(encoder_decoder_model_path, \"ppls.json\"), ppls\n",
    ")\n",
    "\n",
    "save_json(\n",
    "    os.path.join(encoder_decoder_model_path, \"source_vocab.json\"), SOURCE.vocab.stoi\n",
    ")\n",
    "\n",
    "save_json(\n",
    "    os.path.join(encoder_decoder_model_path, \"target_vocab.json\"), TARGET.vocab.stoi\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вариант 2\n",
    "\n",
    "### Модель sequence-to-sequence на основе архитектуры трансформера\n",
    "https://github.com/CyberZHG/keras-transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install --quiet keras-transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>src</th>\n",
       "      <th>trg</th>\n",
       "      <th>cn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>29782</td>\n",
       "      <td>о опричн нс</td>\n",
       "      <td>о опричнинѣ</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>12885</td>\n",
       "      <td>стряпшiйдмитр6йниепауовъ сынъ голее⊗щевъ</td>\n",
       "      <td>стряпчей дмитрей степановъ сынъ голенищевъ</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>172887</td>\n",
       "      <td>отдато граммткв у боахинъ кнть ннъърееви92 хов...</td>\n",
       "      <td>отдать грамотка у боярина кнзь  анъдреевича хо...</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>8469</td>\n",
       "      <td>игналью т⊕уъа3евском[</td>\n",
       "      <td>игнатью трухачевскому</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>164681</td>\n",
       "      <td>показуетъ эвитокъ и рл]ъ0лет4</td>\n",
       "      <td>показуетъ свитокъ и глаголетъ</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                                src  \\\n",
       "521   29782                                        о опричн нс   \n",
       "737   12885           стряпшiйдмитр6йниепауовъ сынъ голее⊗щевъ   \n",
       "740  172887  отдато граммткв у боахинъ кнть ннъърееви92 хов...   \n",
       "660    8469                              игналью т⊕уъа3евском[   \n",
       "411  164681                      показуетъ эвитокъ и рл]ъ0лет4   \n",
       "\n",
       "                                                   trg  cn  \n",
       "521                                        о опричнинѣ  11  \n",
       "737         стряпчей дмитрей степановъ сынъ голенищевъ  40  \n",
       "740  отдать грамотка у боярина кнзь  анъдреевича хо...  62  \n",
       "660                              игнатью трухачевскому  21  \n",
       "411                      показуетъ свитокъ и глаголетъ  29  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "transformer_model_path = \"transformer_model\"\n",
    "if not os.path.exists(transformer_model_path):\n",
    "    os.makedirs(transformer_model_path)\n",
    "\n",
    "\n",
    "strata = df[\"cn\"].values\n",
    "train_df, test_df = train_test_split(df, stratify=strata, train_size=0.9, shuffle=True)\n",
    "\n",
    "\n",
    "train_df.to_csv(os.path.join(transformer_model_path, \"train.tsv\"), sep=\"\\t\", index=False)\n",
    "test_df.to_csv(os.path.join(transformer_model_path, \"test.tsv\"), sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_token_dict(text_list):\n",
    "    token_dict = {\n",
    "        '<PAD>': 0,\n",
    "        '<START>': 1,\n",
    "        '<END>': 2,\n",
    "    }\n",
    "    for text in tqdm(text_list, total=len(text_list)):\n",
    "        for token in text:\n",
    "            if token not in token_dict:\n",
    "                token_dict[token] = len(token_dict)\n",
    "    return token_dict\n",
    "\n",
    "\n",
    "def prepare_data(df, source_token_dict, target_token_dict):\n",
    "    df[\"src_tok\"] = df[\"src\"].apply(tokenize)\n",
    "    df[\"trg_tok\"] = df[\"trg\"].apply(tokenize)\n",
    "\n",
    "    source_tokens = df[\"src_tok\"].tolist()\n",
    "    target_tokens = df[\"trg_tok\"].tolist()\n",
    "\n",
    "    encode_tokens = [['<START>'] + tokens + ['<END>'] for tokens in source_tokens]\n",
    "    decode_tokens = [['<START>'] + tokens + ['<END>'] for tokens in target_tokens]\n",
    "    output_tokens = [tokens + ['<END>', '<PAD>'] for tokens in target_tokens]\n",
    "    \n",
    "    source_max_len = max(map(len, encode_tokens))\n",
    "    target_max_len = max(map(len, decode_tokens))\n",
    "    \n",
    "    encode_tokens = [tokens + ['<PAD>'] * (source_max_len - len(tokens)) for tokens in encode_tokens]\n",
    "    decode_tokens = [tokens + ['<PAD>'] * (target_max_len - len(tokens)) for tokens in decode_tokens]\n",
    "    output_tokens = [tokens + ['<PAD>'] * (target_max_len - len(tokens)) for tokens in output_tokens]\n",
    "    \n",
    "    encode_input = [list(map(lambda x: source_token_dict[x], tokens)) for tokens in encode_tokens]\n",
    "    decode_input = [list(map(lambda x: target_token_dict[x], tokens)) for tokens in decode_tokens]\n",
    "    decode_output = [list(map(lambda x: [target_token_dict[x]], tokens)) for tokens in output_tokens]\n",
    "    \n",
    "    return encode_input, decode_input, decode_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "292900ac86d34423afc4e2adac0459f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=900.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83e89ac1889a4796886aa48bed78505a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=900.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tr_source_token_dict = build_token_dict(train_df.src.tolist())\n",
    "tr_target_token_dict = build_token_dict(train_df.trg.tolist())\n",
    "\n",
    "tr_target_token_dict_inv = {v: k for k, v in tr_target_token_dict.items()}\n",
    "tr_source_token_dict_inv = {v: k for k, v in tr_source_token_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json(\n",
    "    os.path.join(transformer_model_path, \"source_token_dict.json\"), tr_source_token_dict\n",
    ")\n",
    "\n",
    "save_json(\n",
    "    os.path.join(transformer_model_path, \"target_token_dict.json\"), tr_target_token_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras_transformer import get_model\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "EMBED_DIM = 512\n",
    "HIDDEN_DIM = 256\n",
    "HEAD_NUM = 4\n",
    "ENC_NUM = 3\n",
    "DEC_NUM = 3\n",
    "DROPOUT_RATE = 0.2\n",
    "LEARNING_RATE = 0.00001\n",
    "\n",
    "\n",
    "model = get_model(\n",
    "    token_num=max(len(tr_source_token_dict), len(tr_target_token_dict)),\n",
    "    embed_dim=EMBED_DIM,\n",
    "    encoder_num=ENC_NUM,\n",
    "    decoder_num=DEC_NUM,\n",
    "    head_num=HEAD_NUM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    dropout_rate=DROPOUT_RATE,\n",
    "    use_same_embed=False,\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(lr=LEARNING_RATE), loss='sparse_categorical_crossentropy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCH_NUM = 15\n",
    "\n",
    "\n",
    "encode_input, decode_input, decode_output = prepare_data(\n",
    "    train_df, tr_source_token_dict, tr_target_token_dict\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    x=[np.array(encode_input), np.array(decode_input)],\n",
    "    y=np.array(decode_output),\n",
    "    epochs=EPOCH_NUM,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(transformer_model_path, \"transformer_model_base.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценка моделей на внутренней тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install --quiet editdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import editdistance\n",
    "\n",
    "\n",
    "def evaluate(y_true, y_pred, print_num=50):\n",
    "    numCharErr = 0\n",
    "    numCharTotal = 0\n",
    "    numStringOK = 0\n",
    "    numStringTotal = 0\n",
    "    counter = 0\n",
    "\n",
    "    word_eds, word_true_lens = [], []\n",
    "    \n",
    "    for i, pred in enumerate(y_pred):\n",
    "        true = y_true[i]\n",
    "        \n",
    "        numStringOK += 1 if true == pred else 0\n",
    "        \n",
    "        numStringTotal += 1\n",
    "        dist = editdistance.eval(pred, true)\n",
    "        \n",
    "        numCharErr += dist\n",
    "        numCharTotal += len(true)\n",
    "        \n",
    "        pred_words = pred.split()\n",
    "        true_words = true.split()\n",
    "        word_eds.append(editdistance.eval(pred_words, true_words))\n",
    "        word_true_lens.append(len(true_words))\n",
    "        \n",
    "        is_print = np.random.choice([True, False], p=[0.05, 0.95])\n",
    "        if is_print and counter < print_num and len(true) > 15:\n",
    "            print('[OK]' if dist==0 else '[ERR:%d]' % dist,'\"' + true + '\"', '->', '\"' + pred + '\"')\n",
    "            counter += 1\n",
    "\n",
    "    charErrorRate = numCharErr / numCharTotal\n",
    "    wordErrorRate = sum(word_eds) / sum(word_true_lens) \n",
    "    stringAccuracy = numStringOK / numStringTotal\n",
    "    print(\n",
    "        'Character error rate: %f%%. Word error rate: %f%%. String accuracy: %f%%.' % \\\n",
    "        (charErrorRate*100.0,wordErrorRate*100.0, stringAccuracy*100.0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder-decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharTokenizer(object):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.src_stoi = self.config[\"vocab\"][\"src_stoi\"]\n",
    "        self.trg_stoi = self.config[\"vocab\"][\"trg_stoi\"]\n",
    "        self.src_itos = {v: k for k, v in self.src_stoi.items()}\n",
    "        self.trg_itos = {v: k for k, v in self.trg_stoi.items()}\n",
    "        self.eos_token = self.config[\"tok\"][\"eos_token\"]\n",
    "        self.unk_token = self.config[\"tok\"][\"unk_token\"]\n",
    "        self.pad_token = self.config[\"tok\"][\"pad_token\"]\n",
    "        self.sos_token = self.config[\"tok\"][\"sos_token\"]\n",
    "    \n",
    "    def encode(self, sequence):\n",
    "        enc = [self.src_stoi[char] if char in self.src_stoi else self.stoi[self.unk_token_id] for char in list(sequence)] + [self.src_stoi[self.eos_token]]\n",
    "        return torch.tensor(enc).unsqueeze(0)\n",
    "    \n",
    "    def create_mask(self, enc):\n",
    "        return (enc != self.src_stoi[self.pad_token]).unsqueeze(-2)\n",
    "    \n",
    "    def get_length(self, enc):\n",
    "        return torch.tensor(enc.shape[-1], dtype=torch.int64).unsqueeze(0)\n",
    "\n",
    "\n",
    "def load_model(config, device):\n",
    "\n",
    "    model_params = config[\"model\"]\n",
    "    model_path = model_params[\"model_path\"]\n",
    "    emb_size = model_params[\"emb_size\"]\n",
    "    hidden_size = model_params[\"hidden_size\"]\n",
    "    num_layers = model_params[\"num_layers\"]\n",
    "    dropout = model_params[\"dropout\"]\n",
    "\n",
    "    state_dict = torch.load(model_path)\n",
    "    source_dim = state_dict[\"src_embed.weight\"].shape[0]\n",
    "    target_dim = state_dict[\"trg_embed.weight\"].shape[0]\n",
    "\n",
    "    model = EncoderDecoder(\n",
    "        Encoder(emb_size, hidden_size, num_layers=num_layers, dropout=dropout),\n",
    "        Decoder(emb_size, hidden_size, BahdanauAttention(hidden_size), num_layers=num_layers, dropout=dropout),\n",
    "        nn.Embedding(source_dim, emb_size),\n",
    "        nn.Embedding(target_dim, emb_size),\n",
    "        Generator(hidden_size, target_dim)\n",
    "    )\n",
    "\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_json(fname_path):\n",
    "    with open(fname_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "\n",
    "def build_config(encoder_decoder_model_path,\n",
    "                 model_name=\"encoder_decoder_model.pt\",\n",
    "                 emb_size=256,\n",
    "                 hidden_size=512,\n",
    "                 num_layers=2,\n",
    "                 dropout_rate=0.2,\n",
    "                 source_vocab=\"source_vocab.json\",\n",
    "                 target_vocab=\"target_vocab.json\"\n",
    "                ):\n",
    "    config = {\n",
    "        \"model\": {\n",
    "            \"model_path\": os.path.join(encoder_decoder_model_path, model_name),\n",
    "            \"emb_size\": emb_size,\n",
    "            \"hidden_size\": hidden_size,\n",
    "            \"num_layers\": num_layers,\n",
    "            \"dropout\": dropout_rate\n",
    "        },\n",
    "        \"tok\": {\n",
    "            \"pad_token\": PAD_TOKEN,\n",
    "            \"sos_token\": SOS_TOKEN,\n",
    "            \"eos_token\": EOS_TOKEN,\n",
    "            \"unk_token\": UNK_TOKEN\n",
    "        },\n",
    "        \"vocab\": {\n",
    "            \"src_stoi\": load_json(\n",
    "                os.path.join(encoder_decoder_model_path, source_vocab)\n",
    "            ),\n",
    "            \"trg_stoi\": load_json(\n",
    "                os.path.join(encoder_decoder_model_path, target_vocab)\n",
    "            )\n",
    "        }\n",
    "    }\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_copy(sequence, output):\n",
    "    diff = len(sequence) - len(output)\n",
    "    if diff > 0:\n",
    "        return output + sequence[-diff:]\n",
    "    return output\n",
    "\n",
    "\n",
    "def greedy_decode(sequence, model, tokenizer, device, copy=False, max_len=256):\n",
    "    src = tokenizer.encode(sequence).to(device)\n",
    "    src_mask = tokenizer.create_mask(src).to(device)\n",
    "    src_length = tokenizer.get_length(src).to(device)\n",
    "    sos_index = tokenizer.trg_stoi[tokenizer.sos_token]\n",
    "    eos_index = tokenizer.trg_stoi[tokenizer.eos_token]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        encoder_hidden, encoder_final = model.encode(src, src_mask, src_length)\n",
    "        prev_y = torch.ones(1, 1).fill_(sos_index).type_as(src)\n",
    "        trg_mask = torch.ones_like(prev_y)\n",
    "\n",
    "    output = []\n",
    "    hidden = None\n",
    "\n",
    "    for i in range(max_len):\n",
    "        with torch.no_grad():\n",
    "            out, hidden, pre_output = model.decode(\n",
    "              encoder_hidden, encoder_final, src_mask,\n",
    "              prev_y, trg_mask, hidden)\n",
    "            prob = model.generator(pre_output[:, -1])\n",
    "\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.data.item()\n",
    "        output.append(next_word)\n",
    "        prev_y = torch.ones(1, 1).type_as(src).fill_(next_word)\n",
    "    \n",
    "    output = np.array(output)\n",
    "    if eos_index is not None:\n",
    "        first_eos = np.where(output==eos_index)[0]\n",
    "        if len(first_eos) > 0:\n",
    "            output = output[:first_eos[0]]      \n",
    "    \n",
    "    output = \"\".join([tokenizer.trg_itos[token_id] for token_id in output.tolist()])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "encoder_decoder_model_config = build_config(encoder_decoder_model_path=encoder_decoder_model_path)\n",
    "tokenizer = CharTokenizer(config=encoder_decoder_model_config)\n",
    "encoder_decoder_model = load_model(config=encoder_decoder_model_config, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "encoder_decoder_result_path = os.path.join(encoder_decoder_model_path, \"encoder_decoder_results.json\")\n",
    "encoder_decoder_result = load_json(encoder_decoder_result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_decoder_prediction = encoder_decoder_result[\"predictions\"]\n",
    "encoder_decoder_trgs = encoder_decoder_result[\"targets\"]\n",
    "encoder_decoder_srcs = encoder_decoder_result[\"sources\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пример генерации на аугментированных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'отъсихъ конфшенъпри м0рикоградуидущиобрѣеаютсявертоградысултанскіятакожде иъ другуюсторонуградхвелми'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_decoder_srcs[-100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'отъ сихъ коняшенъ при морико граду и дущи обрѣзаются вертограды султанскія такожде изъ другую сторону градовелми'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_decoder_prediction[-100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'отъ сихъ конюшенъ при мори ко граду идущи обрѣтаются вертограды султанскія такожде и зъ другую сторону града велми'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_decoder_trgs[-100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Исходные значения метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERR:8] \"быша сія  6968го\" -> \"дыч3сія6м68бо\"\n",
      "[ERR:5] \"и невидимъ бысть\" -> \"инетидимлбыст\"\n",
      "[ERR:6] \"повѣсть  полезна\" -> \"щовѣсщрполена\"\n",
      "[ERR:4] \"ноября въ 27й день\" -> \"ноябрявъ27йден\"\n",
      "[ERR:7] \"августа въ 18 день\" -> \"авгизтащъ18ден\"\n",
      "[ERR:9] \"о  взятіи  7071го\" -> \"орзят2г7071ххо\"\n",
      "[ERR:5] \"апрѣля въ 28 день\" -> \"апрѣлявъ2йденг\"\n",
      "[ERR:3] \"ноября въ 24 день\" -> \"ноябрявъ24день\"\n",
      "[ERR:3] \"сенке омельянову\" -> \"се8кеомелянову\"\n",
      "[ERR:5] \"куря подъ лимоны\" -> \"кузяпо6ълимоныт\"\n",
      "[ERR:2] \"оношке савостину\" -> \"оношкшсавостину\"\n",
      "[ERR:3] \"но и то тебѣ мало\" -> \"но итотебѣ тало\"\n",
      "[ERR:5] \"гришкѣ мерзлюкину\" -> \"гришаѣмецююкину\"\n",
      "[ERR:4] \"федке ратманцову\" -> \"федкер1тм…нцо7у\"\n",
      "[ERR:3] \"паки  1й  ангелъ\" -> \"па7и 1й  ангплъ\"\n",
      "[ERR:5] \"власку степанову\" -> \"влщвкуьтепжнову\"\n",
      "[ERR:1] \"5 черевъ болшихъ\" -> \"5 черевъболшихъ\"\n",
      "[ERR:2] \"по 140 четвертей\" -> \"по 1ю0 четве2тей\"\n",
      "[ERR:4] \"марта въ 20 день\" -> \"⊕а]та въ 20 дрнѣ\"\n",
      "[ERR:5] \"павлику захарову\" -> \"тав1икузахдровук\"\n",
      "[ERR:4] \"филипку данилову\" -> \"филипоу д[нирнву\"\n",
      "[ERR:5] \"на ныхъ узди  шитіе\" -> \"наныхъуздишитіщ\"\n",
      "[ERR:4] \"сентября въ 12 день\" -> \"сентябрявъ12ден\"\n",
      "[ERR:3] \"августа въ 23 день\" -> \"августа въ23ден\"\n",
      "[ERR:4] \"сентября въ 8 день\" -> \"сентябр7въ8день\"\n",
      "[ERR:4] \"богдашку мажееву\" -> \"рогдашку хаж1пву\"\n",
      "[ERR:4] \"2 сафяна черныхъ\" -> \"д сафяоа че5нсхъ\"\n",
      "[OK] \"обрамку чепелеву\" -> \"обрамку чепелеву\"\n",
      "[ERR:4] \"максимъ куликовъ\" -> \"м]ксимъ к3еиыовъ\"\n",
      "[ERR:2] \"о  на скорнищеве\" -> \"о  на скчрнищете\"\n",
      "[ERR:4] \"волость коурдакъ\" -> \"вол8с2ь коусйакъ\"\n",
      "[ERR:4] \"некраску ножкину\" -> \"некреске 0ожцину\"\n",
      "[ERR:4] \"куря подъ лимоны\" -> \"куоя п2дъ [вмоны\"\n",
      "[ERR:4] \"дениску матвееву\" -> \"деничку 3атв[е у\"\n",
      "[ERR:1] \"полотокъ гусиной\" -> \"п8лотокъ гусиной\"\n",
      "[ERR:4] \"савке назбицково\" -> \"с чк2 назбнцково\"\n",
      "[ERR:3] \"кольской острогъ\" -> \"кольской встыогф\"\n",
      "[OK] \"въ домовой казнѣ\" -> \"въ домовой казнѣ\"\n",
      "[ERR:4] \"взять къ отпуску\" -> \"взять гъ озппшку\"\n",
      "[ERR:4] \"друганку иванову\" -> \"др+санку иупнову\"\n",
      "[OK] \"петрушкѣ плохово\" -> \"петрушкѣ плохово\"\n",
      "[ERR:1] \"въ той же каморѣ\" -> \"въ тнй же каморѣ\"\n",
      "[ERR:3] \"игоне офонасьеву\" -> \"игiне офонъсьэву\"\n",
      "[ERR:3] \"2 книги полустава\" -> \"2 книгипоіустаха\"\n",
      "[ERR:2] \"октября въ 3 день\" -> \"октьбря въ 3 ден\"\n",
      "[ERR:1] \"700 свѣчь салныхъ\" -> \"700 свѣч салныхъ\"\n",
      "[ERR:2] \"шестакъ голышкинъ\" -> \"шестакъголышкднъ\"\n",
      "[ERR:4] \"ноября въ 10 день\" -> \"нояб[я въ10 дфнт\"\n",
      "[ERR:3] \"друганку иванову\" -> \"дрзганiу иваьову\"\n",
      "[ERR:6] \"и не розболокалъ его\" -> \"инарюболокалъего\"\n",
      "Character error rate: 15.647653%. Word error rate: 64.469520%. String accuracy: 4.568930%.\n"
     ]
    }
   ],
   "source": [
    "evaluate(\n",
    "    y_true=encoder_decoder_trgs,\n",
    "    y_pred=encoder_decoder_srcs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Целевые значения метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERR:3] \"авгута въ 8 день\" -> \"а голта въ 8 день\"\n",
      "[ERR:2] \"и соромъ и не смѣю\" -> \"и соромъ и не мѣню\"\n",
      "[OK] \"ноября въ 22 день\" -> \"ноября въ 22 день\"\n",
      "[ERR:2] \"корова рыжа безъ\" -> \"коромъ рыжа безъ\"\n",
      "[OK] \"ноября въ 24 день\" -> \"ноября въ 24 день\"\n",
      "[ERR:5] \"ваше   низлагаетъ\" -> \"вашенть злагаетъ\"\n",
      "[ERR:2] \"онъ же тамерланъ\" -> \"онъ же тамъ рланъ\"\n",
      "[ERR:2] \"куря подъ лимоны\" -> \"кузя подъ лимоный\"\n",
      "[ERR:2] \"апрѣля въ 6 день\" -> \"апрѣлянъ 6 день\"\n",
      "[ERR:1] \"но и то тебѣ мало\" -> \"но и то тебѣ тало\"\n",
      "[OK] \"тренке михаилову\" -> \"тренке михаилову\"\n",
      "[ERR:2] \"о измѣнѣ донской\" -> \"о имѣнѣ чонской\"\n",
      "[ERR:1] \"путилу неболсину\" -> \"путилу наболсину\"\n",
      "[ERR:2] \"майя въ 28й день\" -> \"майя въ 12й день\"\n",
      "[ERR:4] \"177 г іюля въ 22 день\" -> \"177 г іюля 192 день\"\n",
      "[ERR:2] \"на ныхъ узди  шитіе\" -> \"на ныхъ уздишитіе\"\n",
      "[ERR:1] \"селуяшке фатееву\" -> \"келуяшке фатееву\"\n",
      "[ERR:1] \"списокъ съ рѣчей\" -> \"списокъ съ вѣчей\"\n",
      "[ERR:4] \"казаня латынскые\" -> \"казанъ латеншкіе\"\n",
      "[ERR:4] \"такъ   отскочили\" -> \"дакъ   восковили\"\n",
      "[OK] \"гришкѣ васильеву\" -> \"гришкѣ васильеву\"\n",
      "[ERR:5] \"слова тъ хептаръ\" -> \"слава въ непетръ\"\n",
      "[ERR:1] \"богдашку мажееву\" -> \"богдашку макееву\"\n",
      "[ERR:3] \"по 250 четвертей\" -> \"по 200 четверти\"\n",
      "[ERR:3] \"максимку греневу\" -> \"макуилку гренову\"\n",
      "[ERR:1] \"ивану кректышеву\" -> \"ивану крестышеву\"\n",
      "[ERR:1] \"куземке ончютину\" -> \"куземке ончитину\"\n",
      "[ERR:4] \"тренке зиновьеву\" -> \"трецке миноющеву\"\n",
      "[ERR:3] \"щучина просолная\" -> \"щучина протурная\"\n",
      "[ERR:3] \"воеводцкихъ жъ кг\" -> \"влеподцкихъ жъ къ\"\n",
      "[ERR:2] \"списокъ съ отписи\" -> \"иписовъ съ отписи\"\n",
      "[OK] \"октября во 2 день\" -> \"октября во 2 день\"\n",
      "[OK] \"въ бѣломъ городѣ\" -> \"въ бѣломъ городѣ\"\n",
      "[ERR:1] \"вологоцкіе дворы\" -> \"вологоцкіе двору\"\n",
      "[ERR:4] \"177 г іюня въ 23 день\" -> \"177 г іюдновъ 13 день\"\n",
      "[OK] \"въ казанской приказъ\" -> \"въ казанской приказъ\"\n",
      "[ERR:2] \"бой литвѣ съ рязанцы\" -> \"бойли твѣ съ рязанцы\"\n",
      "[ERR:2] \"3 пищали затинныхъ\" -> \"3 гищали катинныхъ\"\n",
      "[OK] \"февраля въ 17 день\" -> \"февраля въ 17 день\"\n",
      "[ERR:1] \"о сибирстей странѣ\" -> \"о сибирскей странѣ\"\n",
      "[ERR:1] \"генваря въ 8 день\" -> \"генвари въ 8 день\"\n",
      "[ERR:1] \"ноября въ 25 день\" -> \"ноября въ 2й день\"\n",
      "[ERR:4] \"бегичку трофимову\" -> \"бемечка трофимовъ\"\n",
      "[OK] \"степанъ карауловъ\" -> \"степанъ карауловъ\"\n",
      "[OK] \"петрушкѣ дронову\" -> \"петрушкѣ дронову\"\n",
      "[ERR:1] \"степанку данилову\" -> \"степанку даньлову\"\n",
      "[ERR:3] \"дениско далмановъ\" -> \"деньско калкановъ\"\n",
      "[ERR:4] \"григорью панютину\" -> \"фригорья пасатину\"\n",
      "[OK] \"лобъ подъ хрѣномъ\" -> \"лобъ подъ хрѣномъ\"\n",
      "[ERR:2] \"штанишки   ветхіе\" -> \" табишки   ветхіе\"\n",
      "Character error rate: 9.112059%. Word error rate: 35.221303%. String accuracy: 15.528948%.\n"
     ]
    }
   ],
   "source": [
    "evaluate(\n",
    "    y_true=encoder_decoder_trgs,\n",
    "    y_pred=encoder_decoder_prediction\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.python.util.deprecation as deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "\n",
    "\n",
    "te_encode_input, te_decode_input, te_decode_output = prepare_data(\n",
    "    test_df, tr_source_token_dict, tr_target_token_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_transformer import decode\n",
    "\n",
    "\n",
    "def transformer_decode(decode_input, vocab=tr_target_token_dict_inv):\n",
    "    decode_input = [x for x in decode_input if not vocab[x] in (\"<PAD>\", \"<END>\", \"<START>\")]\n",
    "    return \"\".join(map(lambda x: vocab[x], decode_input))\n",
    "\n",
    "\n",
    "decoded = decode(\n",
    "    model,\n",
    "    te_encode_input,\n",
    "    start_token=tr_target_token_dict['<START>'],\n",
    "    end_token=tr_target_token_dict['<END>'],\n",
    "    pad_token=tr_target_token_dict['<PAD>'],\n",
    "    temperature=1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['при себѣ внука своего нарекъ великимъ княземъ всеа русіи',\n",
       " 'по нашему указу отпущены были  на соловки и съ соловковъ пришли къ намъ къ москвѣ',\n",
       " 'покупалъ тѣ лотки приказу тайныхъ дѣлъ подьячей перфирей оловяниковъ',\n",
       " 'была въ венецы процесія празднуютъ католики тотъ день святому кресту христову',\n",
       " 'злѣ сотворили есте и невозможно вамъ будетъ предъ старымъ отцемъ отвещати']"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_transformer_test_true = [transformer_decode(x) for x in te_decode_input]\n",
    "y_transformer_test_true[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['хри семѣ влука своего наремъ великимъ княземъ всеа русіи',\n",
       " 'по нашемъ указу отпущены были  на соловки и съ половкова пришли коламѣ къ москвѣ',\n",
       " 'покупалъ тѣ лотки приказу тайныхъ дѣлъ подьячей пертирей оловяниковъ',\n",
       " 'бобравъ вентцы прицесія празануютъ затолаки томъ день святому кресту пристовъ',\n",
       " 'злѣсотворбли естеи нево можно вамъ будетъ предъ старымъ омцемъ отвощати']"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_transformer_test_pred = [transformer_decode(x) for x in decoded]\n",
    "y_transformer_test_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERR:15] \"а твоего государева денежнаго и хлѣбнаго жалованяя окладъ мнѣ холопу твоему не учиненъ\" -> \"я твоего го4[д⊕кева денешнаго и хлѣбна[о жалованяяокл8дъ м]ѣ хол6п2 твоему н2 учиферъ\"\n",
      "[ERR:11] \"а имена  стрелцомъ и росписка въ росходномъ столпу\" -> \"аимена  стреицомъ и 8осп7ика въ твсх6дномъ 8тоѣпх\"\n",
      "[ERR:10] \"и абіе нападе на нихъ ужасъ велій и посрамлени побегоша\" -> \"и аыіе 9впазе9а нищъ ужажъ велай и посрамлени побегдша\"\n",
      "[ERR:11] \"зде государь  въ ангилове еровова досталь дасеваемъ\" -> \"здегосуда5ввъанеиловеерововадостальдксеваемъ\"\n",
      "[ERR:8] \"писана на москвѣ  7141го апрѣля въ 15 день\" -> \"писана нф москвѣ  7141го апзв]я вн 1ъ дешс\"\n",
      "[ERR:19] \"ноября въ 27 день велѣно быти на михайлове на княжъ васильево мѣсто морткина резанцу дею иванову сыну рохманинову\" -> \"ноябрявъ27денвелѣнобытинамихайловенакняжъвасилевомѣстоморткинарезанцудеюивановусынурохманинову\"\n",
      "[ERR:1] \"да въ одоеве жъ кропивенское  съ одоевскимъ вмѣстѣ подъ соборную церковь въ каменныхъ полаткехъ\" -> \"да въ одоеве жъ кропивенское  съ одоевскимъ вмѣстѣ подъ соборную церков въ каменныхъ полаткехъ\"\n",
      "[ERR:4] \"уже трубятъ къ столу\" -> \"уже орубятъеъ стллу\"\n",
      "[ERR:14] \"по имени тѣхъ поминати которымъ ясти просвира виноватому на обличеніе\" -> \"п6 имене тѣхъ поми6ати котсрымъ ясiи просвиьа ниэоватоме н6 об…ѣчін]е\"\n",
      "[ERR:3] \"переводилъ абдулъ байцынъ\" -> \"пекеводилъ абдрлъ байцынб\"\n",
      "[ERR:6] \"же проидоша по суху посреде моря\" -> \"ощпр⊗идоша по суху по⊗реде мор0\"\n",
      "[OK] \"всего тритцать рублевъ четыре алтына\" -> \"всего тритцать рублевъ четыре алтына\"\n",
      "[OK] \"богатства же ихъ безчисленная разграбиша нечестивіи\" -> \"богатства же ихъ безчисленная разграбиша нечестивіи\"\n",
      "[ERR:16] \"списывали бы зъ грамоты сѣя списки и съсылали бы въ  во  страны въскоре\" -> \"с⊗исыбафи нх зж грамори яѣш спбски и с1сдлали бы въ  во  сѣраны въс⊗2ре\"\n",
      "[ERR:3] \"дающе же отъ воза по полутора рубля но мало вземлющихъ вшій ради и червей и смрада ради злого\" -> \"дающе же отъ воа по полутора рубля но мало вемлющихъ вшій ради и червей и смрада ради лого\"\n",
      "[ERR:16] \"во дворѣ вдова овдотьица ивановская жена бирюлина у  три сына филимонко да якушко тимошка во дьячкахъ\" -> \"водворѣвдоваовдотьицаивановскаяженабирюлинаутрисынафилимонкодаякушкотимошкаводьячкахъ\"\n",
      "[ERR:4] \"суконца багрецу аршинъ безъ вершка\" -> \"суконца б]г8ецу арш9нъ безъ выршка\"\n",
      "[OK] \" государь и святѣйшій государь патріархъ слушали\" -> \" государь и святѣйшій государь патріархъ слушали\"\n",
      "[ERR:15] \"7092 посланіемъ божіимъ уготовись часъ пріиде на воиновъ смерть\" -> \"7092пос4аніемъ 3ожиим7 жготояися щ7съ пріидена во⊗нывъ сеецть\"\n",
      "[ERR:5] \"изъ литвы пришелъ нестеръ\" -> \"изъвидвы пришеьъ неятеръ\"\n",
      "[ERR:12] \"и какъ пожалуетъ на отпѣванью будетъ и прикащикомъ дати патріарху и на  соборъ десять рублевъ\" -> \"икакъпожалуетъна отпѣваню будетъиприкащикомъдатипатріарху и насоборъ десятрублевъ\"\n",
      "[ERR:6] \"приказалъ государь имянно\" -> \"прижазалъ оосiдаѣ1 иэянно\"\n",
      "[ERR:5] \"20 аршинъ алтасу золото съ серебромъ\" -> \"20аршинъалтасузолотосъсеребромъ\"\n",
      "[ERR:6] \"въ переславль  залеской ко князю семену елетцкому\" -> \"въ цереславл  залеской ко кыяю семену елптцкомы\"\n",
      "[ERR:5] \"7 аршинъ дароговъ красновишневыхъ\" -> \"7аршинъ йароговъ красновиэневысъ5\"\n",
      "[ERR:4] \"и тако царь дербышъ и воеводы укрепиша градъ\" -> \"итако царьдербышъи воеводы укрепишаградъ\"\n",
      "[ERR:2] \"и грамота имъ на ввозная на то  дана такова\" -> \"и грамоса имъ н2 ввозная на то  дана такова\"\n",
      "[ERR:12] \"шапка краснаго сукна опушена черною овчиною исподъ черевя лисѣ\" -> \"шъпка крпкнаго сугна опушеню червою овченчю iсходъ чщре1я лисѣ\"\n",
      "[ERR:17] \"а маришкино воровство въ асторохани велѣть писать да про ивашково заруцкого также выписать\" -> \"у іаш1емину воровс3во ъ зсiорохани велеть п[сатз дг пшо ивашково заруцкого также вып4сать\"\n",
      "[ERR:4] \"аще которую жену дитя томить долго напиши на бумагѣ\" -> \"аще которую жену дитя томряь долго напиши на бщмцгѣ\"\n",
      "[ERR:4] \"а въ черницахъ бысть дней 18\" -> \"а въ чернибахъ быст днфй д8\"\n",
      "[ERR:2] \"кружива нитного 3 аршъ шириною четверти\" -> \"кружиуа нитног6 3 аршъ шириною четверти\"\n",
      "[ERR:7] \"да на воротехъ вѣстовой колоколъ  а по другой отписки тотъ колоколъ розбитъ\" -> \"да на во0отехъ жѣстквой кощоколъ  а по другой отписки то4ъ долоколъ розбитж\"\n",
      "[ERR:6] \"а тѣ деньги взяты изъ монастырскаго приказу и збору за даточныхъ\" -> \"а тѣ деньги вяты иъ монастырсчаго прикузу и зборм за даточныхъг\"\n",
      "[ERR:8] \"и мы великій государь посланника твоего приняли и рѣчи его выслушали любително\" -> \"и мы великій яосудар хосланника тв0йго пяиняли л рѣчи его выслушали тюбително\"\n",
      "[ERR:14] \"а на утріи всенощнаго не бываетъ а благовѣстятъ къ заутрени за 5 часовъ\" -> \"а н2 ут8іи вх+нощного ке бываетъ ] благовѣс0ят3 къ заутрени 27 5 чдйавъ\"\n",
      "[ERR:8] \"а верви куплены для  мѣры\" -> \"авервикупл0ныдля7мэры6\"\n",
      "[ERR:10] \"поручи камка зелена опушены камкою лазоревою\" -> \"поручиккм1а зелена опьшоны камловэазоровою\"\n",
      "[ERR:7] \"и сотвори господь преславная тогда\" -> \"исотворигоспцжьпреславнаятпгда\"\n",
      "[ERR:10] \"а теренинской де князецъ сказалъ имъ я де ни съ кѣмъ не ссылаюсь\" -> \"атеренинскойшекнязецъ сказалъимъяде ни съ кѣмънессылаюс\"\n",
      "[ERR:7] \"прошлыхъ же  ячмено въ житницѣ на лицо 161 чети\" -> \"прошлыхъ же  яя⊗е5о въ житницѣ на л7цо 1ъ1 чеъс\"\n",
      "[ERR:13] \"а мучило  крѣпко билась и ротъ у  ворочало подъ ухо на обѣ стороны\" -> \"8мучизо  крѣпко бил8сщ и ротъ 4  в⊕рочало ]лръ ухо на обѣсторяэы\"\n",
      "[ERR:19] \"вси бо бѣды и напасти въ веце семъ и вся злая бываемая человѣкомъ нѣсть бѣда но милость божія\" -> \"iси бо бѣдр и напасти въ всце семъ г фся зяая 0ывѣе⊕ая челхвнкхмъ нѣсть б+да ео ъллость 3+жін\"\n",
      "[ERR:18] \"посадцкихъ людей съ пищалми 250 человѣкъ да съ бердыши и съ рогатины 58 человѣкъ\" -> \"восайцкухй людеп съ пкщ7лми 2ъ0 человѣав ча съ тэхдыуи и съ ыогати9ы58 человѣкъ\"\n",
      "[ERR:18] \"шапочному мастеру бориску кондратьеву за шапку тмозелену настрафилну на лисицѣ 14 алъ 2 д\" -> \"шапочномумастеруборискутондратевуашапкутмозеленунастрбфилнунатисицѣ14алъ42д\"\n",
      "[ERR:3] \"по указу великаго государя т изъ приказу большого приходу на росходы восмъ тысячь рублевъ\" -> \"по указу великаго государя т иъ прикау болшого приходу на росходы восмъ тысячь рублевъ\"\n",
      "[ERR:7] \"9 наволочокъ изголовенныхъ застѣнки нитные \" -> \"9 наволачокъ ижг⊗лцвекныхъ застѣнвн нитные \"\n",
      "[ERR:1] \"7031го  фоминское сентября 28 день дали по иванѣ по андреевичѣ челяднине\" -> \"7031го  фоминское сентября 28 ден дали по иванѣ по андреевичѣ челяднине\"\n",
      "[ERR:3] \"мощи иванна предтечи кость\" -> \"мови иванна предтези кост\"\n",
      "[ERR:2] \"ондрюшке безсчастному\" -> \"онерюшке бесчастному\"\n",
      "Character error rate: 15.756570%. Word error rate: 64.765463%. String accuracy: 4.477930%.\n"
     ]
    }
   ],
   "source": [
    "evaluate(\n",
    "    y_true=y_transformer_test_true,\n",
    "    y_pred=test_df[\"src\"].tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERR:7] \"а твоего государева денежнаго и хлѣбнаго жалованяя окладъ мнѣ холопу твоему не учиненъ\" -> \"и твоего государева денешнаго и хлѣбнаго жалованся окладъ мнѣ холопъ твоему на учитеръ\"\n",
      "[OK] \"и казанцы били челомъ на царя шигъалѣя\" -> \"и казанцы били челомъ на царя шигъалѣя\"\n",
      "[ERR:6] \"къ  росписи игнатъ еремѣевъ руку приложилъ\" -> \"къ росписи понать зеремѣехъ руку приложилъ\"\n",
      "[ERR:2] \"и изъ тѣхъ 3 пищали худы стрѣлять нелзя\" -> \"и изъ тѣхъ 3 пищали суды стрѣлять неля\"\n",
      "[ERR:3] \"срокъ троицынъ день\" -> \"свокъ троицынъ бегь\"\n",
      "[ERR:10] \"двъ данилка кощіева померлъ въ прошломъ во 192 году\" -> \"двъ данилца короска прехолъ въ прошхомъ во 192 году\"\n",
      "[ERR:5] \"на коломнѣ князь иванъ княжъ ивановъ сынъ шеховской\" -> \"на колочнѣ князь аванъ княжъ ивановъ сынъ нехосикой\"\n",
      "[ERR:6] \"головы стрелецкіе всѣхъ приказовъ\" -> \"полоды стрялецкіе вся зъ приказовъ\"\n",
      "[ERR:2] \"іюня въ 9 день пріѣхалъ въ дорогобужъ\" -> \"іюня въ 9 день пріѣхалъ въ дерогобутъ\"\n",
      "[ERR:7] \"о посланіи царя кучюма сына своего маметкула на рускіе вои ратію\" -> \"о посланіи царь кучюма сына своего мареткова на рускіе пои радіи\"\n",
      "[OK] \"и проклинаше прелесть ихъ злочестивую и пророка ихъ махомета и писанія его\" -> \"и проклинаше прелесть ихъ злочестивую и пророка ихъ махомета и писанія его\"\n",
      "[ERR:3] \"паче же о совершонном поряткѣ\" -> \"паче же о ствѣршонном порятку\"\n",
      "[ERR:2] \"во дворѣ гришка ермолинъ сынъ кузнецъ у нево сынъ якушко году\" -> \"во дворѣ гришка ермолинъ сынъ кузнецъ у нево сынъ якушкого ду\"\n",
      "[ERR:11] \"посланники жъ пришедше возвестиша сія что было повелѣнное имъ изрещи\" -> \"послансикихъ пришедшевозвестяша рья что сыпо повелѣнной имъ изращи\"\n",
      "[ERR:7] \"у пятницкихъ воротъ 3 затинщики съ пищалми\" -> \"упринецкихъ вератъ 3 затинщикъ съ пищалми\"\n",
      "[ERR:11] \"а яз васъ велю и съ вашими животы и со всею рухлядію проводити до тѣхъ мѣстъ гдѣ вы похотите\" -> \"а яновасъ велю и стовашями живаты и со всею рухлядію промодити до тѣхъ взятъ гдѣ въ похотите\"\n",
      "[ERR:13] \"манатья съ источники байберекъ подпушена камкою лазоревою\" -> \"данагой же источники бабберекъ помлошенъ камкою казоревню\"\n",
      "[ERR:3] \"выписать исъ писцовыхъ книгъ и изъ  росписи\" -> \"выписать изъ писцовыхъ кневъ и изъ  росписи\"\n",
      "[ERR:1] \"и изгна царя и съ царицами оттуду\" -> \"и изгна царя и съ царицами оттуму\"\n",
      "[ERR:6] \"по склейкамъ скрѣпа діакъ давыдъ деревинъ\" -> \"по скрейкамъ скрѣжа діаки даныхъ феревинъ\"\n",
      "[ERR:6] \"съ перевозу съ великіе рѣки откупныхъ денегъ на нынѣшней на 128й годъ противъ 127го году семь рублевъ\" -> \"съ перевозу съ велшкіе мѣки откупныхъ денегъ на отнѣшней на 128й годъ притивъ 177го году семь рублевъ\"\n",
      "[ERR:3] \"въ лѣто 6815 преставися князь констянтинъ борисовичь ростовскій въ ордѣ\" -> \"въ лѣто 6895 преставися князь констянтинъ борисовичь постовскій въ орнѣ\"\n",
      "[ERR:7] \"за семены приполону у того овса 223 четверти\" -> \"на семены приполотъ у того овсалія четверти\"\n",
      "[ERR:15] \"богъ прославися а крестъ коснусь на небеси рабъ божій имярекъ имѣетъ на себѣ михаила и гаврила\" -> \"богъ прославися а престъ косписана небись махъ коязъ имярекъ имѣеръ на себѣ михаила и гаврилъ\"\n",
      "[ERR:3] \"бысть видѣніе страшно и ужаса исполнено\" -> \"бысть видѣніе страша о и угаса исполнено\"\n",
      "[ERR:1] \"деньги взялъ и росписался въ росходномъ столпу стремянной конюхъ иванъ соймановъ\" -> \"деньги взялъ и росписался въ росходномъ столпустремянной конюхъ иванъ соймановъ\"\n",
      "[ERR:13] \"били мнѣ челомъ  богородицы іосифова монастыря игуменъ васьянъ зъ братьею\" -> \"быси мнѣ чего зъ  богородицы іерикова моростыря игоманъ васіянъ зъ братьею\"\n",
      "[ERR:1] \"четвертке офонасьеву\" -> \"четвертке офонасеву\"\n",
      "[ERR:16] \"на томъ же дворѣ поделаны великіе полаты гдѣ выливаютъ пушки \" -> \"та томъ же сторъ подолаю хосликіено латы гда вынивайтъ пушки \"\n",
      "[ERR:2] \"князь микита княжъ дмитреевъ сынъ горчаковъ\" -> \"князь мукипа княжъ дмитреевъ сынъ горчаковъ\"\n",
      "[ERR:13] \"имѣетъ медіоланъ вокругъ себя валъ земляной  изрядной крѣпости\" -> \"имѣетъ меникванъ волшугъ себя валъ семьяной  израдной грѣпеени\"\n",
      "[ERR:11] \"о драгунехъ и о салдатехъ о кормовыхъ и о даточныхъ людехъ\" -> \"о драй у нехъ и осалдатехъ озормопыхъ и ода е очныхъ людехъ\"\n",
      "[ERR:1] \"писанъ на москвѣ  7171 ноября въ 19 день\" -> \"писанъ на москвѣ  7171 ноября въ 39 день\"\n",
      "[ERR:9] \"да бобровникомъ юшкѣ обакумову 3 человѣкомъ корму на день 4 алъ\" -> \"да бобротникомъ казѣ онакумову 3 челцѣнкомъ корму на день 4 асъ\"\n",
      "[ERR:5] \"теопомпусъ царь спартански власть государскую привелъ былъ къ мѣрѣ у лакедимоновъ\" -> \"че опомпусъ царь спартански власть госудатскую привелъ вылъ къ мѣрѣ улакедимоновъ\"\n",
      "[ERR:8] \"ибо вскорѣ по семъ то   7019го начася въ туркахъ веліе междоусобіе\" -> \"ибо всковѣ по семъ то   7019го начася въ тоткахъ ведіе пождоу содіе\"\n",
      "[ERR:4] \"147го сентября въ 10 день подалъ атаманъ донской осипъ лосевъ\" -> \"145го сентября въ 10 день подалъ атаманъ допсквы осипъ лосевъ\"\n",
      "[ERR:1] \"не яз тя недугъ уговариваю  уговариваетъ тя святая баба соломонида\" -> \"не я тя недугъ уговариваю  уговариваетъ тя святая баба соломонида\"\n",
      "[ERR:5] \"всего на волоку всякихъ людей 77 ч\" -> \"всего на волокъ велкихъ люней 17 ч\"\n",
      "[ERR:8] \"дѣлаютъ однорядки въ крымскую посылку\" -> \"дѣлаюты однася дкидъ тремскую посылку\"\n",
      "[ERR:3] \"а нравомъ грубъ и къ бывающимъ въ запрещеніяхъ косенъ къ разрѣшеніямъ\" -> \"а правомъ грубъ и къ бывающимъ въ заплещеніяхъ косенъ къ разрашеніямъ\"\n",
      "[ERR:1] \"генваря въ 17 день\" -> \"генваря въ 19 день\"\n",
      "[ERR:1] \"а у купчіе на затыли послухи\" -> \"а у купчіе на затили послухи\"\n",
      "[ERR:3] \"въ родословной прежней книгѣ написано\" -> \"въ рудославной прежней книгѣ написаной\"\n",
      "[ERR:4] \"артенабусъ   чтетъ\" -> \"артена бучъ чтетъ\"\n",
      "[ERR:3] \"кондрашкѣ труфанову\" -> \"кондедшкѣ труканову\"\n",
      "[ERR:6] \"обьери венецкой дикаго цвѣту 6 аршъ 6 вершкъ\" -> \"обье вязвенецкій дикаго цвѣту 6 аршъ 6 верткъ\"\n",
      "[ERR:4] \"борисъ михайловъ сынъ бибиковъ\" -> \"боресъ михайловъ сынъ болсковъ\"\n",
      "[OK] \"на оборотѣ  195 декабря въ 26 день взять къ дѣлу\" -> \"на оборотѣ  195 декабря въ 26 день взять къ дѣлу\"\n",
      "[ERR:2] \"писанъ на москвѣ  7154го мая въ 10 день\" -> \"писанъ на москвѣ  7133го мая въ 10 день\"\n",
      "Character error rate: 9.938054%. Word error rate: 38.140039%. String accuracy: 15.023792%.\n"
     ]
    }
   ],
   "source": [
    "evaluate(\n",
    "    y_true=y_transformer_test_true,\n",
    "    y_pred=y_transformer_test_pred\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценка моделей на валидационной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERR:11] \"[а iменно при дворѣ аглинском] былъ\" -> \"га iмен но приддрѣ ат лин кком ]былъ\"\r\n",
      "[ERR:10] \"iз лагору 11 д iюля 1711 петръ\" -> \"iзлагоруд iюля 1окюх етръ\"\r\n",
      "[ERR:10] \"которым позволяется всѣ\" -> \"ко то ромм по оляотя пѣ\"\r\n",
      "[ERR:6] \"в милости i призрѣнi\" -> \"вмимости i празрык\"\r\n",
      "[ERR:8] \"і двины не можно л слюзоф здѣлат там\" -> \"i двиныио мож нол сло зоф здѣлат там\"\r\n",
      "[ERR:2] \"ли\" -> \"а\"\r\n",
      "[ERR:6] \"колко офицероф наперет\" -> \"солко офицеродна перб\"\r\n",
      "[ERR:13] \"от речи жижи въ 15 д iюля петръ\" -> \"отрiнжиживъя д iюля ует еу\"\r\n",
      "[ERR:6] \"буде же ск\" -> \"вудецс ве\"\r\n",
      "[ERR:6] \"хто такого сыщет iли возвестит тому от\" -> \"пхто такого сыет iли возветит то муут\"\r\n"
     ]
    }
   ],
   "source": [
    "!head val_prediction.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def parse(data):\n",
    "    y_true, y_pred = [], []\n",
    "    for line in data:\n",
    "        true, recognized = re.findall('\".+\"', line)[0].split(\"->\")\n",
    "        true, recognized = true.strip(' \"'), recognized.strip(' \"')\n",
    "        y_true.append(true)\n",
    "        y_pred.append(recognized)\n",
    "    return y_true, y_pred\n",
    "\n",
    "        \n",
    "def read_validation_data(fname):\n",
    "    with open(fname, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = [line for line in f.read().split(\"\\n\") if line]\n",
    "        return parse(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_true, y_val_pred = read_validation_data(\"val_prediction.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[а iменно при дворѣ аглинском] былъ -> га iмен но приддрѣ ат лин кком ]былъ\n"
     ]
    }
   ],
   "source": [
    "print(y_val_true[0], \"->\", y_val_pred[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Исходные показатели на валидационной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERR:8] \"в помераниi [которой вѣдомости\" -> \"в померанич ра саторой водомоси\"\n",
      "[ERR:10] \"купъцофъ рукомесленных i духовъных\" -> \"к упъдофо гукомесленныхх чдох явъных\"\n",
      "Character error rate: 27.366609%. Word error rate: 88.963964%. String accuracy: 0.000000%.\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_val_true, y_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERR:25] \"линею остъвестъ чрез тѣ мѣста гдѣ доткнулис вы\" -> \"и отъ оста асибъ призовъ мѣтя гдѣ дот князнѣ\"\n",
      "[ERR:17] \"ежели б возможно чтоб свадббѣ сына моего быт\" -> \"еделе вом моно чтоб сваглѣ о намого его\"\n",
      "[ERR:8] \"не iзнужит но держат во въся\" -> \"не iзну жаи но держать двѣся\"\n",
      "[ERR:2] \"так как нам самому\" -> \"тай как нах самому\"\n",
      "[ERR:16] \"тит низом верхъ надлежит же знат что у указу\" -> \"и на том в ебрая надехлит же знать что у уко ]\"\n",
      "[ERR:12] \"рыя въ 60 пушек то б на нижней полубѣ полукар\" -> \"рыя въ то  пушек той нанихъ ней полу бѣ полуку\"\n",
      "[ERR:14] \"трактъ от киева до старадуба [а ска\" -> \"тристь отки ева доста доду на галка\"\n",
      "Character error rate: 32.573150%. Word error rate: 89.189189%. String accuracy: 0.000000%.\n"
     ]
    }
   ],
   "source": [
    "# Encoder-decoder model\n",
    "\n",
    "encoder_decoder_generated = [\n",
    "    greedy_decode(cv_pred, model=encoder_decoder_model, tokenizer=tokenizer, device=DEVICE) for cv_pred in y_val_pred\n",
    "]\n",
    "\n",
    "evaluate(\n",
    "    y_true=y_val_true,\n",
    "    y_pred=encoder_decoder_generated\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>trg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>га iмен но приддрѣ ат лин кком ]былъ</td>\n",
       "      <td>[а iменно при дворѣ аглинском] былъ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iзлагоруд iюля 1окюх етръ</td>\n",
       "      <td>iз лагору 11 д iюля 1711 петръ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ко то ромм по оляотя пѣ</td>\n",
       "      <td>которым позволяется всѣ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>вмимости i празрык</td>\n",
       "      <td>в милости i призрѣнi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i двиныио мож нол сло зоф здѣлат там</td>\n",
       "      <td>і двины не можно л слюзоф здѣлат там</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    src                                   trg\n",
       "0  га iмен но приддрѣ ат лин кком ]былъ   [а iменно при дворѣ аглинском] былъ\n",
       "1             iзлагоруд iюля 1окюх етръ        iз лагору 11 д iюля 1711 петръ\n",
       "2               ко то ромм по оляотя пѣ               которым позволяется всѣ\n",
       "3                    вмимости i празрык                  в милости i призрѣнi\n",
       "4  i двиныио мож нол сло зоф здѣлат там  і двины не можно л слюзоф здѣлат там"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformer model\n",
    "\n",
    "val_df = pd.DataFrame([(y, y_val_true[i]) for i, y in enumerate(y_val_pred)], columns=[\"src\", \"trg\"])\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "va_encode_input, va_decode_input, va_decode_output = prepare_data(\n",
    "    val_df, tr_source_token_dict, tr_target_token_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "va_decoded = decode(\n",
    "    model,\n",
    "    va_encode_input,\n",
    "    start_token=tr_target_token_dict['<START>'],\n",
    "    end_token=tr_target_token_dict['<END>'],\n",
    "    pad_token=tr_target_token_dict['<PAD>'],\n",
    "    temperature=1.0,\n",
    "    top_k=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[а iменно при дворѣ аглинском] былъ',\n",
       " 'iз лагору 11 д iюля 1711 петръ',\n",
       " 'которым позволяется всѣ',\n",
       " 'в милости i призрѣнi',\n",
       " 'і двины не можно л слюзоф здѣлат там']"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_transformer_val_true = [transformer_decode(x) for x in va_decode_input]\n",
    "y_transformer_val_true[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['на iмен но придарѣ ат линском обылъ',\n",
       " 'iзлагоруда іюля покладеръ',\n",
       " 'ко то ромъ по олтотя пѣ',\n",
       " 'вмимости i празры',\n",
       " 'i двины то можиною сло золоздѣлат там']"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_transformer_val_pred = [transformer_decode(x) for x in va_decoded]\n",
    "y_transformer_val_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERR:7] \"линно i дайте нам знат дабы\" -> \"и но iдахтенам знатдабя\"\n",
      "Character error rate: 27.366609%. Word error rate: 88.963964%. String accuracy: 0.000000%.\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_val_true, y_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERR:6] \"колко офицероф наперет\" -> \"солко офицеродна перб\"\n",
      "[ERR:9] \"нами сужъдено i вина\" -> \"нае мми бу ржено вина\"\n",
      "[ERR:14] \"а когъда похочеш протиф норда часы дѣлат\" -> \"а к года подо че протифь норданы а садѣлять\"\n",
      "[ERR:11] \"как дѣлат наклоном часы\" -> \"андрѣат на помом на 1\"\n",
      "[ERR:19] \"повѣi ради мололюдства афицерофъ\" -> \"погдо ржи многи  ни завицемъ\"\n",
      "Character error rate: 32.228916%. Word error rate: 90.315315%. String accuracy: 0.000000%.\n"
     ]
    }
   ],
   "source": [
    "evaluate(\n",
    "    y_true=y_transformer_val_true,\n",
    "    y_pred=y_transformer_val_pred\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
